{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of features from a given correlation matrix\n",
    "\n",
    "https://gmarti.gitlab.io//qfin/2020/08/14/correlation-matrix-features.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T22:37:48.923104Z",
     "start_time": "2020-12-05T22:37:44.152810Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import squareform\n",
    "import fastcluster\n",
    "import networkx as nx\n",
    "from statsmodels.stats.correlation_tools import corr_nearest\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T22:37:58.442874Z",
     "start_time": "2020-12-05T22:37:58.436889Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mst_stats(corr):\n",
    "    dist = (1 - corr) / 2\n",
    "    G = nx.from_numpy_matrix(dist) \n",
    "    mst = nx.minimum_spanning_tree(G)\n",
    "\n",
    "    features = pd.Series()\n",
    "    features['mst_avg_shortest'] = nx.average_shortest_path_length(mst)\n",
    "\n",
    "\n",
    "    closeness_centrality = (pd\n",
    "                            .Series(list(nx\n",
    "                                         .closeness_centrality(mst)\n",
    "                                         .values()))\n",
    "                            .describe())\n",
    "    for stat in closeness_centrality.index[1:]:\n",
    "        features[f'mst_centrality_{stat}'] = closeness_centrality[stat]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T22:38:09.543551Z",
     "start_time": "2020-12-05T22:38:09.476728Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_features_from_correl(model_corr):\n",
    "    n = model_corr.shape[0]\n",
    "    a, b = np.triu_indices(n, k=1)\n",
    "    \n",
    "    features = pd.Series()\n",
    "    coefficients = model_corr[a, b].flatten()\n",
    "\n",
    "    coeffs = pd.Series(coefficients)\n",
    "    coeffs_stats = coeffs.describe()\n",
    "    for stat in coeffs_stats.index[1:]:\n",
    "        features[f'coeffs_{stat}'] = coeffs_stats[stat]\n",
    "    features['coeffs_1%'] = coeffs.quantile(q=0.01)\n",
    "    features['coeffs_99%'] = coeffs.quantile(q=0.99)\n",
    "    features['coeffs_10%'] = coeffs.quantile(q=0.1)\n",
    "    features['coeffs_90%'] = coeffs.quantile(q=0.9)\n",
    "\n",
    "\n",
    "    # eigenvals\n",
    "    eigenvals, eigenvecs = np.linalg.eig(model_corr)\n",
    "    permutation = np.argsort(eigenvals)[::-1]\n",
    "    eigenvals = eigenvals[permutation]\n",
    "    eigenvecs = eigenvecs[:, permutation]\n",
    "\n",
    "    pf_vector = eigenvecs[:, np.argmax(eigenvals)]\n",
    "    if len(pf_vector[pf_vector < 0]) > len(pf_vector[pf_vector > 0]):\n",
    "        pf_vector = -pf_vector\n",
    "\n",
    "    features['varex_eig1'] = float(eigenvals[0] / sum(eigenvals))\n",
    "    features['varex_eig_top5'] = (float(sum(eigenvals[:5])) / \n",
    "                                  float(sum(eigenvals)))\n",
    "    features['varex_eig_top30'] = (float(sum(eigenvals[:30])) / \n",
    "                                   float(sum(eigenvals)))\n",
    "    # Marcenko-Pastur (RMT)\n",
    "    T, N = 252, n\n",
    "    MP_cutoff = (1 + np.sqrt(N / T))**2\n",
    "    # variance explained by eigenvals outside of the MP distribution\n",
    "    features['varex_eig_MP'] = (\n",
    "        float(sum([e for e in eigenvals if e > MP_cutoff])) /\n",
    "        float(sum(eigenvals)))\n",
    "    \n",
    "    # determinant\n",
    "    features['determinant'] = np.prod(eigenvals)\n",
    "    \n",
    "    # condition number\n",
    "    features['condition_number'] = abs(eigenvals[0]) / abs(eigenvals[-1])\n",
    "\n",
    "\n",
    "    # stats of the first eigenvector entries\n",
    "    pf_stats = pd.Series(pf_vector).describe()\n",
    "    if pf_stats['mean'] < 1e-5:\n",
    "        return None\n",
    "    for stat in pf_stats.index[1:]:\n",
    "        features[f'pf_{stat}'] = float(pf_stats[stat])\n",
    "\n",
    "\n",
    "    # stats on the MST\n",
    "    features = pd.concat([features, compute_mst_stats(model_corr)],\n",
    "                         axis=0)\n",
    "\n",
    "    # stats on the linkage\n",
    "    dist = np.sqrt(2 * (1 - model_corr))\n",
    "    for algo in ['ward', 'single', 'complete', 'average']:\n",
    "        Z = fastcluster.linkage(dist[a, b], method=algo)\n",
    "        features[f'coph_corr_{algo}'] = cophenet(Z, dist[a, b])[0]\n",
    "\n",
    "    return features.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T22:38:15.016845Z",
     "start_time": "2020-12-05T22:38:15.000886Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_dataset_features(mats):\n",
    "    all_features = []\n",
    "    for i in range(mats.shape[0]):\n",
    "        model_corr = mats[i, :, :]\n",
    "\n",
    "        features = compute_features_from_correl(model_corr)\n",
    "\n",
    "        if features is not None:\n",
    "            all_features.append(features)\n",
    "    \n",
    "    return pd.concat(all_features, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T22:38:24.042083Z",
     "start_time": "2020-12-05T22:38:23.848602Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'empirical_matrices.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0da2ad8ca8ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mempirical_matrices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'empirical_matrices.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mempirical_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_dataset_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempirical_matrices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mempirical_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'empirical_matrices.npy'"
     ]
    }
   ],
   "source": [
    "empirical_matrices = np.load('empirical_matrices.npy')\n",
    "\n",
    "empirical_features = compute_dataset_features(empirical_matrices)\n",
    "\n",
    "empirical_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
